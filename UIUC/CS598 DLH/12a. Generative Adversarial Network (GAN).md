Create new samples that resemble training data. There are two neural networks, generator and discriminator. 
- Generator: creating realistic but synthetic samples
- Discriminator: differentiating synthetic and real samples
$$\min_G \min_D V(D, G) = \mathbb{E}_{x \sim p_{\rm data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_{z}(z)}[\log (1 - D(G(z)))]$$
Iteratively, we train $D$ for a few epochs, then train $G$ for a few epochs.
Convergence of GAN training is still an open problem.
Overtraining can lead to performance degradation.
# Application
- MedGAN: Generate synthetic EHR
